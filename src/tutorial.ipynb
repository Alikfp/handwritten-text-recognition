{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oMty1YwuWHpN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65a3db53806d4f6bb172c90f6041523d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_971a844a84194143b572bf6c16298aa5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03ee3beb68f24fa786f4418685fd6d2c",
              "IPY_MODEL_fd1c56e7264b410c97520e849688ab3b"
            ]
          }
        },
        "971a844a84194143b572bf6c16298aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03ee3beb68f24fa786f4418685fd6d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_f46ce28672604a458e2906ac0324deb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6.56MB of 6.56MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc1ef13228094c7380283b384385c6a8"
          }
        },
        "fd1c56e7264b410c97520e849688ab3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6234e582780e4a2a9c4a1cdd341cc732",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a978fdf3e344c709c6f90a2f08660ac"
          }
        },
        "f46ce28672604a458e2906ac0324deb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc1ef13228094c7380283b384385c6a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6234e582780e4a2a9c4a1cdd341cc732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a978fdf3e344c709c6f90a2f08660ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurflor23/handwritten-text-recognition/blob/master/src/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP-v0E_S-mQP"
      },
      "source": [
        "<img src=\"https://github.com/arthurflor23/handwritten-text-recognition/blob/master/doc/image/header.png?raw=true\" />\n",
        "\n",
        "# Handwritten Text Recognition using TensorFlow 2.x\n",
        "\n",
        "This tutorial shows how you can use the project [Handwritten Text Recognition](https://github.com/arthurflor23/handwritten-text-recognition) in your Google Colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMty1YwuWHpN"
      },
      "source": [
        "## 1 Localhost Environment\n",
        "\n",
        "We'll make sure you have the project in your Google Drive with the datasets in HDF5. If you already have structured files in the cloud, skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39blvPTPQJpt"
      },
      "source": [
        "### 1.1 Datasets\n",
        "\n",
        "The datasets that you can use:\n",
        "\n",
        "a. [Bentham](http://www.transcriptorium.eu/~tsdata/)\n",
        "\n",
        "b. [IAM](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database)\n",
        "\n",
        "c. [Rimes](http://www.a2ialab.com/doku.php?id=rimes_database:start)\n",
        "\n",
        "d. [Saint Gall](https://fki.tic.heia-fr.ch/databases/saint-gall-database)\n",
        "\n",
        "e. [Washington](https://fki.tic.heia-fr.ch/databases/washington-database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVBGMLifWQwl"
      },
      "source": [
        "### 1.2 Raw folder\n",
        "\n",
        "On localhost, download the code project from GitHub and extract the chosen dataset (or all if you prefer) in the **raw** folder. Don't change anything of the structure of the dataset, since the scripts were made from the **original structure** of them. Your project directory will be like this:\n",
        "\n",
        "```\n",
        ".\n",
        "├── raw\n",
        "│   ├── bentham\n",
        "│   │   ├── BenthamDatasetR0-GT\n",
        "│   │   └── BenthamDatasetR0-Images\n",
        "│   ├── iam\n",
        "│   │   ├── ascii\n",
        "│   │   ├── forms\n",
        "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
        "│   │   ├── lines\n",
        "│   │   └── xml\n",
        "│   ├── rimes\n",
        "│   │   ├── eval_2011\n",
        "│   │   ├── eval_2011_annotated.xml\n",
        "│   │   ├── training_2011\n",
        "│   │   └── training_2011.xml\n",
        "│   ├── saintgall\n",
        "│   │   ├── data\n",
        "│   │   ├── ground_truth\n",
        "│   │   ├── README.txt\n",
        "│   │   └── sets\n",
        "│   └── washington\n",
        "│       ├── data\n",
        "│       ├── ground_truth\n",
        "│       ├── README.txt\n",
        "│       └── sets\n",
        "└── src\n",
        "    ├── data\n",
        "    │   ├── evaluation.py\n",
        "    │   ├── generator.py\n",
        "    │   ├── preproc.py\n",
        "    │   ├── reader.py\n",
        "    │   ├── similar_error_analysis.py\n",
        "    ├── main.py\n",
        "    ├── network\n",
        "    │   ├── architecture.py\n",
        "    │   ├── layers.py\n",
        "    │   ├── model.py\n",
        "    └── tutorial.ipynb\n",
        "\n",
        "```\n",
        "\n",
        "After that, create virtual environment and install the dependencies with python 3 and pip:\n",
        "\n",
        "> ```python -m venv .venv && source .venv/bin/activate```\n",
        "\n",
        "> ```pip install -r requirements.txt```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyLRbAwsWSYA"
      },
      "source": [
        "### 1.3 HDF5 files\n",
        "\n",
        "Now, you'll run the *transform* function from **main.py**. For this, execute on **src** folder:\n",
        "\n",
        "> ```python main.py --source=<DATASET_NAME> --transform```\n",
        "\n",
        "Your data will be preprocess and encode, creating and saving in the **data** folder. Now your project directory will be like this:\n",
        "\n",
        "\n",
        "```\n",
        ".\n",
        "├── data\n",
        "│   ├── bentham.hdf5\n",
        "│   ├── iam.hdf5\n",
        "│   ├── rimes.hdf5\n",
        "│   ├── saintgall.hdf5\n",
        "│   └── washington.hdf5\n",
        "├── raw\n",
        "│   ├── bentham\n",
        "│   │   ├── BenthamDatasetR0-GT\n",
        "│   │   └── BenthamDatasetR0-Images\n",
        "│   ├── iam\n",
        "│   │   ├── ascii\n",
        "│   │   ├── forms\n",
        "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
        "│   │   ├── lines\n",
        "│   │   └── xml\n",
        "│   ├── rimes\n",
        "│   │   ├── eval_2011\n",
        "│   │   ├── eval_2011_annotated.xml\n",
        "│   │   ├── training_2011\n",
        "│   │   └── training_2011.xml\n",
        "│   ├── saintgall\n",
        "│   │   ├── data\n",
        "│   │   ├── ground_truth\n",
        "│   │   ├── README.txt\n",
        "│   │   └── sets\n",
        "│   └── washington\n",
        "│       ├── data\n",
        "│       ├── ground_truth\n",
        "│       ├── README.txt\n",
        "│       └── sets\n",
        "└── src\n",
        "    ├── data\n",
        "    │   ├── evaluation.py\n",
        "    │   ├── generator.py\n",
        "    │   ├── preproc.py\n",
        "    │   ├── reader.py\n",
        "    │   ├── similar_error_analysis.py\n",
        "    ├── main.py\n",
        "    ├── network\n",
        "    │   ├── architecture.py\n",
        "    │   ├── layers.py\n",
        "    │   ├── model.py\n",
        "    └── tutorial.ipynb\n",
        "\n",
        "```\n",
        "\n",
        "Then upload the **data** and **src** folders in the same directory in your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jydsAcWgWVth"
      },
      "source": [
        "## 2 Google Drive Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk3e7YJiXzSl"
      },
      "source": [
        "### 2.1 TensorFlow 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7twXyNGXtbJ"
      },
      "source": [
        "Make sure the jupyter notebook is using GPU mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHw4tODULT1Z"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMg-B5PH9h3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55559492-162a-4749-f65d-2169f1688200"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name != \"/device:GPU:0\":\n",
        "    raise SystemError(\"GPU device not found\")\n",
        "\n",
        "print(\"Found GPU at: {}\".format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyMv5wyDXxqc"
      },
      "source": [
        "### 2.2 Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5gj6qwoX9W3"
      },
      "source": [
        "Mount your Google Drive partition.\n",
        "\n",
        "**Note:** *\\\"Colab Notebooks/handwritten-text-recognition/src/\\\"* was the directory where you put the project folders, specifically the **src** folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACQn1iBF9k9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411100c8-80a5-4e5d-fc45-d24b4be42f49"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"./gdrive\", force_remount=True)\n",
        "\n",
        "%cd \"./gdrive/My Drive/Colab Notebooks/HTR/src/\"\n",
        "!ls -l"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/HTR/src\n",
            "total 37\n",
            "drwx------ 2 root root  4096 Jul  7 03:27 data\n",
            "-rw------- 1 root root  9074 Jul  7 01:22 main.py\n",
            "drwx------ 2 root root  4096 Jul  7 03:27 network\n",
            "-rw------- 1 root root 16138 Jul  6 00:24 tutorial.ipynb\n",
            "drwx------ 2 root root  4096 Jul 13 02:27 wandb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwogUA8RZAyp"
      },
      "source": [
        "After mount, you can see the list os files in the project folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fj7fSngY1IX"
      },
      "source": [
        "## 3 Set Python Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Q4cOlWhNl3"
      },
      "source": [
        "### 3.1 Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvqL2Eq5ZUc7"
      },
      "source": [
        "First, let's define our environment variables.\n",
        "\n",
        "Set the main configuration parameters, like input size, batch size, number of epochs and list of characters. This make compatible with **main.py** and jupyter notebook:\n",
        "\n",
        "* **dataset**: \"bentham\", \"iam\", \"rimes\", \"saintgall\", \"washington\"\n",
        "\n",
        "* **arch**: network to run: \"bluche\", \"puigcerver\", \"flor\"\n",
        "\n",
        "* **epochs**: number of epochs\n",
        "\n",
        "* **batch_size**: number size of the batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy2FD0bTtIch"
      },
      "source": [
        "# set of models previously trained on\n",
        "data_sources = ['washington']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qpr3drnGMWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df25e009-067c-4375-f24a-618bade4a5c2"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import string\n",
        "\n",
        "# define parameters\n",
        "source = \"bentham\"\n",
        "arch = \"flor\"\n",
        "epochs = 12\n",
        "batch_size = 64\n",
        "\n",
        "# define paths\n",
        "source_path = os.path.join(\"..\", \"data\", f\"{source}.hdf5\")\n",
        "\n",
        "# Change\n",
        "new_model = int(input ('Would you like to train a new model, or update the previous weights? (0:UPDATE , 1:NEW)'))\n",
        "\n",
        "if new_model :  # new_model\n",
        "  data_sources = [source]\n",
        "  output_path = os.path.join(\"..\", \"output\", source, arch)\n",
        "  checkpoint_path = os.path.join(output_path, \"checkpoint_weights.hdf5\")\n",
        "\n",
        "else :  # update\n",
        "  data_sources.append(source)\n",
        "  output_path = os.path.join(\"..\", \"output\", \"_\".join(data_sources) , arch)\n",
        "  checkpoint_path = os.path.join(\"..\", \"output\", \"_\".join(data_sources[:-1]) , arch, \"checkpoint_weights.hdf5\")\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# define input size, number max of chars per line and list of valid chars\n",
        "input_size = (1024, 128, 1)\n",
        "max_text_length = 128\n",
        "charset_base = string.printable[:95]\n",
        "\n",
        "print(\"data sources of the upcoming model :\", *data_sources)\n",
        "print(\"source:\", source_path)\n",
        "print(\"output\", output_path)\n",
        "print(\"checkpoint path\", checkpoint_path)\n",
        "print(\"charset:\", charset_base)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Would you like to train a new model, or update the previous weights? (0:UPDATE , 1:NEW)0\n",
            "data sources of the upcoming model : washington bentham\n",
            "source: ../data/bentham.hdf5\n",
            "output ../output/washington_bentham/flor\n",
            "checkpoint path ../output/washington/flor/checkpoint_weights.hdf5\n",
            "charset: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFextshOhTKr"
      },
      "source": [
        "### 3.2 DataGenerator Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfZ1mfvsanu1"
      },
      "source": [
        "The second class is **DataGenerator()**, responsible for:\n",
        "\n",
        "* Load the dataset partitions (train, valid, test);\n",
        "\n",
        "* Manager batchs for train/validation/test process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k9vpNzMIAi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2abe0d1-e0ed-4834-cdb9-82a00010ff1e"
      },
      "source": [
        "from data.generator import DataGenerator\n",
        "dtgen = DataGenerator(source=source_path,\n",
        "                      batch_size=batch_size,\n",
        "                      charset=charset_base,\n",
        "                      max_text_length=max_text_length)\n",
        "\n",
        "print(f\"Train images: {dtgen.size['train']}\")\n",
        "print(f\"Validation images: {dtgen.size['valid']}\")\n",
        "print(f\"Test images: {dtgen.size['test']}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train images: 8807\n",
            "Validation images: 1372\n",
            "Test images: 820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OdgNLK0hYAA"
      },
      "source": [
        "### 3.3 HTRModel Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHktk8AFcnKy"
      },
      "source": [
        "The third class is **HTRModel()**, was developed to be easy to use and to abstract the complicated flow of a HTR system. It's responsible for:\n",
        "\n",
        "* Create model with Handwritten Text Recognition flow, in which calculate the loss function by CTC and decode output to calculate the HTR metrics (CER, WER and SER);\n",
        "\n",
        "* Save and load model;\n",
        "\n",
        "* Load weights in the models (train/infer);\n",
        "\n",
        "* Make Train/Predict process using *generator*.\n",
        "\n",
        "To make a dynamic HTRModel, its parameters are the *architecture*, *input_size* and *vocab_size*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV0GreStISTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ec0937-868e-4e54-db70-cb12ebb7df7a"
      },
      "source": [
        "from network.model import HTRModel\n",
        "# create and compile HTRModel\n",
        "model = HTRModel(architecture=arch,\n",
        "                input_size=input_size,\n",
        "                vocab_size=dtgen.tokenizer.vocab_size,\n",
        "                beam_width=10,\n",
        "                stop_tolerance=20,\n",
        "                reduce_tolerance=15)\n",
        "\n",
        "model.compile(learning_rate=0.001)\n",
        "model.summary(output_path, \"summary.txt\")\n",
        "\n",
        "# get default callbacks and load checkpoint weights file (HDF5) if exists\n",
        "model.load_checkpoint(target=checkpoint_path)\n",
        "\n",
        "callbacks = model.get_callbacks(logdir=output_path, checkpoint=checkpoint_path, verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 1024, 128, 1)]    0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 512, 64, 16)       160       \n",
            "_________________________________________________________________\n",
            "p_re_lu_6 (PReLU)            (None, 512, 64, 16)       16        \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 512, 64, 16)       112       \n",
            "_________________________________________________________________\n",
            "full_gated_conv2d_5 (FullGat (None, 512, 64, 16)       4640      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 512, 64, 32)       4640      \n",
            "_________________________________________________________________\n",
            "p_re_lu_7 (PReLU)            (None, 512, 64, 32)       32        \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 512, 64, 32)       224       \n",
            "_________________________________________________________________\n",
            "full_gated_conv2d_6 (FullGat (None, 512, 64, 32)       18496     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 256, 16, 40)       10280     \n",
            "_________________________________________________________________\n",
            "p_re_lu_8 (PReLU)            (None, 256, 16, 40)       40        \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 256, 16, 40)       280       \n",
            "_________________________________________________________________\n",
            "full_gated_conv2d_7 (FullGat (None, 256, 16, 40)       28880     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256, 16, 40)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 256, 16, 48)       17328     \n",
            "_________________________________________________________________\n",
            "p_re_lu_9 (PReLU)            (None, 256, 16, 48)       48        \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 256, 16, 48)       336       \n",
            "_________________________________________________________________\n",
            "full_gated_conv2d_8 (FullGat (None, 256, 16, 48)       41568     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256, 16, 48)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 128, 4, 56)        21560     \n",
            "_________________________________________________________________\n",
            "p_re_lu_10 (PReLU)           (None, 128, 4, 56)        56        \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 128, 4, 56)        392       \n",
            "_________________________________________________________________\n",
            "full_gated_conv2d_9 (FullGat (None, 128, 4, 56)        56560     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128, 4, 56)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 128, 4, 64)        32320     \n",
            "_________________________________________________________________\n",
            "p_re_lu_11 (PReLU)           (None, 128, 4, 64)        64        \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 128, 4, 64)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 128, 2, 64)        0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 128, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128, 256)          198144    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128, 256)          65792     \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128, 256)          296448    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128, 104)          26728     \n",
            "=================================================================\n",
            "Total params: 825,592\n",
            "Trainable params: 824,312\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1fnz0Eugqru"
      },
      "source": [
        "## 4 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1mLOcqYgsO-"
      },
      "source": [
        "The training process is similar to the *fit()* of the Keras. After training, the information (epochs and minimum loss) is save."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P6MSoxCISlD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "65a3db53806d4f6bb172c90f6041523d",
            "971a844a84194143b572bf6c16298aa5",
            "03ee3beb68f24fa786f4418685fd6d2c",
            "fd1c56e7264b410c97520e849688ab3b",
            "f46ce28672604a458e2906ac0324deb1",
            "fc1ef13228094c7380283b384385c6a8",
            "6234e582780e4a2a9c4a1cdd341cc732",
            "1a978fdf3e344c709c6f90a2f08660ac"
          ]
        },
        "outputId": "ca19e7c9-fce6-47c2-c599-92427b2c87e4"
      },
      "source": [
        "! pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "# 1. Start a new run\n",
        "wandb.init(project='OCR', entity='ali_kfp')\n",
        "\n",
        "# 2. Save model inputs and hyperparameters\n",
        "config = wandb.config\n",
        "config.learning_rate = 0.01\n",
        "  \n",
        "  \n",
        "# to calculate total and average time per epoch\n",
        "start_time = datetime.datetime.now()\n",
        "h = model.fit(x=dtgen.next_train_batch(),\n",
        "              epochs=epochs,\n",
        "              steps_per_epoch=dtgen.steps['train'],\n",
        "              validation_data=dtgen.next_valid_batch(),\n",
        "              validation_steps=dtgen.steps['valid'],\n",
        "              callbacks=[WandbCallback(), callbacks],\n",
        "              shuffle=True,\n",
        "              verbose=1)\n",
        "\n",
        "total_time = datetime.datetime.now() - start_time\n",
        "\n",
        "loss = h.history['loss']\n",
        "val_loss = h.history['val_loss']\n",
        "\n",
        "min_val_loss = min(val_loss)\n",
        "min_val_loss_i = val_loss.index(min_val_loss)\n",
        "\n",
        "time_epoch = (total_time / len(loss))\n",
        "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
        "\n",
        "t_corpus = \"\\n\".join([\n",
        "    f\"Total train images:      {dtgen.size['train']}\",\n",
        "    f\"Total validation images: {dtgen.size['valid']}\",\n",
        "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
        "    f\"Total time:              {total_time}\",\n",
        "    f\"Time per epoch:          {time_epoch}\",\n",
        "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
        "    f\"Total epochs:            {len(loss)}\",\n",
        "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
        "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
        "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
        "])\n",
        "\n",
        "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
        "    lg.write(t_corpus)\n",
        "    print(t_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.33)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.18)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2xfuu8d9) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 18942<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65a3db53806d4f6bb172c90f6041523d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 6.55MB of 6.55MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/gdrive/My Drive/Colab Notebooks/HTR/src/wandb/run-20210713_022841-2xfuu8d9/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/gdrive/My Drive/Colab Notebooks/HTR/src/wandb/run-20210713_022841-2xfuu8d9/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>145.51595</td></tr><tr><td>val_loss</td><td>148.41048</td></tr><tr><td>_runtime</td><td>75</td></tr><tr><td>_timestamp</td><td>1626143396</td></tr><tr><td>_step</td><td>11</td></tr><tr><td>best_val_loss</td><td>148.41048</td></tr><tr><td>best_epoch</td><td>11</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▂▁▁▁▇▁▄▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▂▁▁▁▃▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▂▂▃▃▄▅▆▆▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▃▄▅▆▆▇▇█</td></tr><tr><td>_step</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">tough-cosmos-23</strong>: <a href=\"https://wandb.ai/ali_kfp/OCR/runs/2xfuu8d9\" target=\"_blank\">https://wandb.ai/ali_kfp/OCR/runs/2xfuu8d9</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2xfuu8d9). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.33<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">misty-firebrand-24</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ali_kfp/OCR\" target=\"_blank\">https://wandb.ai/ali_kfp/OCR</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/ali_kfp/OCR/runs/23xina8u\" target=\"_blank\">https://wandb.ai/ali_kfp/OCR/runs/23xina8u</a><br/>\n",
              "                Run data is saved locally in <code>/content/gdrive/My Drive/Colab Notebooks/HTR/src/wandb/run-20210713_023658-23xina8u</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "137/138 [============================>.] - ETA: 0s - loss: 171.7229"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13g7tDjWgtXV"
      },
      "source": [
        "## 5 Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddO26OT-g_QK"
      },
      "source": [
        "The predict process is similar to the *predict* of the Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9iHL6tmaL_j"
      },
      "source": [
        "from data import preproc as pp\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# predict() function will return the predicts with the probabilities\n",
        "predicts, _ = model.predict(x=dtgen.next_test_batch(),\n",
        "                            steps=dtgen.steps['test'],\n",
        "                            ctc_decode=True,\n",
        "                            verbose=1)\n",
        "\n",
        "# decode to string\n",
        "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
        "ground_truth = [x.decode() for x in dtgen.dataset['test']['gt']]\n",
        "\n",
        "total_time = datetime.datetime.now() - start_time\n",
        "\n",
        "# mount predict corpus file\n",
        "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
        "    for pd, gt in zip(predicts, ground_truth):\n",
        "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")\n",
        "   \n",
        "for i, item in enumerate(dtgen.dataset['test']['dt'][:10]):\n",
        "    print(\"=\" * 1024, \"\\n\")\n",
        "    cv2_imshow(pp.adjust_to_see(item))\n",
        "    print(ground_truth[i])\n",
        "    print(predicts[i], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JcAs3Q3WNJ-"
      },
      "source": [
        "## 6 Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LuZBRepWbom"
      },
      "source": [
        "Evaluation process is more manual process. Here we have the `ocr_metrics`, but feel free to implement other metrics instead. In the function, we have three parameters: \n",
        "\n",
        "* predicts\n",
        "* ground_truth\n",
        "* norm_accentuation (calculation with/without accentuation)\n",
        "* norm_punctuation (calculation with/without punctuation marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gCwEYdKWOPK"
      },
      "source": [
        "from data import evaluation\n",
        "\n",
        "evaluate = evaluation.ocr_metrics(predicts, ground_truth)\n",
        "\n",
        "e_corpus = \"\\n\".join([\n",
        "    f\"Total test images:    {dtgen.size['test']}\",\n",
        "    f\"Total time:           {total_time}\",\n",
        "    f\"Time per item:        {total_time / dtgen.size['test']}\\n\",\n",
        "    f\"Metrics:\",\n",
        "    f\"Character Error Rate: {evaluate[0]:.8f}\",\n",
        "    f\"Word Error Rate:      {evaluate[1]:.8f}\",\n",
        "    f\"Sequence Error Rate:  {evaluate[2]:.8f}\"\n",
        "])\n",
        "\n",
        "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
        "    lg.write(e_corpus)\n",
        "    print(e_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}